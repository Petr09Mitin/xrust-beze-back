{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84164f380eea4428",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T16:11:53.754327Z",
     "start_time": "2025-04-02T16:11:49.837175Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f87115e235af10c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T16:11:53.757339Z",
     "start_time": "2025-04-02T16:11:53.754835Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa91630f55b49b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T16:11:55.513372Z",
     "start_time": "2025-04-02T16:11:53.757339Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset.csv', encoding='utf-8')\n",
    "dataset_2 = pd.read_csv('dataset_random.csv', encoding='utf-8')\n",
    "dataset_3 = pd.concat([dataset_2, dataset_2], ignore_index=True)\n",
    "dataset_4 = pd.read_csv('dataset_random_en.csv', encoding='utf-8')\n",
    "dataset_5 = pd.read_csv('mixed_dataset.csv', encoding='utf-8')\n",
    "\n",
    "dataset_6 = pd.read_csv('dataset_random_2.csv', encoding='utf-8')\n",
    "dataset_7 = pd.read_csv('dataset_random_en_2.csv', encoding='utf-8')\n",
    "dataset_8 = pd.read_csv('mixed_dataset_2.csv', encoding='utf-8')\n",
    "general_dataset = pd.concat([dataset_6, dataset_7, dataset_8], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df86b199ea8d4f22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:28:00.323549Z",
     "start_time": "2025-04-02T15:28:00.321127Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# === 1. Генерация искажённых форм ===\n",
    "\n",
    "\n",
    "# === 4. Обучение модели ===\n",
    "def train_baseline_model(df, model=None):\n",
    "    X = df['text']\n",
    "    y = df['label']\n",
    "\n",
    "    # Символьные n-граммы позволяют распознавать искажённые формы\n",
    "    vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 5))\n",
    "    X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:25:31.658281Z",
     "start_time": "2025-04-02T15:25:06.209121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     25132\n",
      "           1       1.00      0.96      0.98     25184\n",
      "\n",
      "    accuracy                           0.98     50316\n",
      "   macro avg       0.98      0.98      0.98     50316\n",
      "weighted avg       0.98      0.98      0.98     50316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_baseline_model(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeef8361f1c1ca43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:00:24.155609Z",
     "start_time": "2025-04-02T15:00:12.294662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     15779\n",
      "           1       1.00      0.91      0.95     15769\n",
      "\n",
      "    accuracy                           0.96     31548\n",
      "   macro avg       0.96      0.96      0.95     31548\n",
      "weighted avg       0.96      0.96      0.95     31548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_baseline_model(dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fceb9c99c85afb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:00:44.643203Z",
     "start_time": "2025-04-02T15:00:44.638287Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9db646f54693f083",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:44:34.140186Z",
     "start_time": "2025-04-02T13:44:12.724578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     31771\n",
      "           1       1.00      0.93      0.97     31325\n",
      "\n",
      "    accuracy                           0.97     63096\n",
      "   macro avg       0.97      0.97      0.97     63096\n",
      "weighted avg       0.97      0.97      0.97     63096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_baseline_model(dataset_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18348485d1e958db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:44:42.148894Z",
     "start_time": "2025-04-02T13:44:39.626366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      4709\n",
      "           1       0.96      0.88      0.92      4659\n",
      "\n",
      "    accuracy                           0.92      9368\n",
      "   macro avg       0.93      0.92      0.92      9368\n",
      "weighted avg       0.93      0.92      0.92      9368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_baseline_model(dataset_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb76b05f24e92564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:45:07.883378Z",
     "start_time": "2025-04-02T13:44:49.176984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.95     20555\n",
      "           1       0.99      0.89      0.94     20377\n",
      "\n",
      "    accuracy                           0.94     40932\n",
      "   macro avg       0.95      0.94      0.94     40932\n",
      "weighted avg       0.95      0.94      0.94     40932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_baseline_model(dataset_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3744a9914360c84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:45:19.487487Z",
     "start_time": "2025-04-02T13:45:19.481223Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_compl = pd.concat([dataset_3, dataset_4, dataset_5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80961d1e444a34ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:46:09.337416Z",
     "start_time": "2025-04-02T13:45:21.104267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     56729\n",
      "           1       1.00      0.94      0.97     56667\n",
      "\n",
      "    accuracy                           0.97    113396\n",
      "   macro avg       0.97      0.97      0.97    113396\n",
      "weighted avg       0.97      0.97      0.97    113396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_baseline_model(dataset_compl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878d72a414d2948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597f8dc64166002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae9407b3ae46de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29c52ae2d754f7f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:48:04.629829Z",
     "start_time": "2025-04-02T13:47:52.373531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     15779\n",
      "           1       1.00      0.91      0.95     15769\n",
      "\n",
      "    accuracy                           0.96     31548\n",
      "   macro avg       0.96      0.96      0.95     31548\n",
      "weighted avg       0.96      0.96      0.95     31548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_baseline_model(dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a4c90f96d038a09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:48:16.307902Z",
     "start_time": "2025-04-02T13:48:04.629829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     15779\n",
      "           1       1.00      0.91      0.95     15769\n",
      "\n",
      "    accuracy                           0.96     31548\n",
      "   macro avg       0.96      0.96      0.95     31548\n",
      "weighted avg       0.96      0.96      0.95     31548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_baseline_model(dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e717d922b374b24d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:48:28.407924Z",
     "start_time": "2025-04-02T13:48:16.307902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     15779\n",
      "           1       1.00      0.91      0.95     15769\n",
      "\n",
      "    accuracy                           0.96     31548\n",
      "   macro avg       0.96      0.96      0.95     31548\n",
      "weighted avg       0.96      0.96      0.95     31548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_baseline_model(dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63c29b6e7f427675",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:48:28.420926Z",
     "start_time": "2025-04-02T13:48:28.407924Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb0df768ca3199f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:51:11.824774Z",
     "start_time": "2025-04-02T13:51:11.820833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1226980"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(general_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf3e6b88cb6f9ccf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:50:34.049715Z",
     "start_time": "2025-04-02T13:49:01.162016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96    122992\n",
      "           1       0.99      0.92      0.96    122404\n",
      "\n",
      "    accuracy                           0.96    245396\n",
      "   macro avg       0.96      0.96      0.96    245396\n",
      "weighted avg       0.96      0.96      0.96    245396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset_8 = pd.read_csv(general_dataset, encoding='utf-8')\n",
    "train_baseline_model(general_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "id": "d9ac63e97f0e7f21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T16:51:13.757127Z",
     "start_time": "2025-04-02T16:51:13.754124Z"
    }
   },
   "source": [
    "def train_baseline_model_2(df, model=None, vectorizer=None):\n",
    "    X = df['text']\n",
    "    y = df['label']\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38d2ded208e55a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(2, 5))\n",
    "model = LogisticRegression(max_iter=1000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b48fc01c3294089e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    122992\n",
      "           1       1.00      0.95      0.97    122404\n",
      "\n",
      "    accuracy                           0.97    245396\n",
      "   macro avg       0.97      0.97      0.97    245396\n",
      "weighted avg       0.97      0.97      0.97    245396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_baseline_model_2(general_dataset, model, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb986d1b5de520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "103d43a072432fc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:36:22.138773Z",
     "start_time": "2025-04-02T15:36:22.136750Z"
    }
   },
   "outputs": [],
   "source": [
    "test_1 = \"Ну всё, приплыли!\"\n",
    "test_2 = \"Ну всё, пиздец!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbfcf8d5895cd743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:36:44.130374Z",
     "start_time": "2025-04-02T15:36:44.128113Z"
    }
   },
   "outputs": [],
   "source": [
    "x = vec.transform([test_1, test_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a55f188a6b06622f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:36:48.398011Z",
     "start_time": "2025-04-02T15:36:48.394060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53163949, 0.46836051],\n",
       "       [0.1136535 , 0.8863465 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4158d8f47a8fb4df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:45:40.046106Z",
     "start_time": "2025-04-02T15:45:40.030478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51980334, 0.48019666]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_3 = \"В 1782 году Карло Мария Буонапарте получил концессию и королевский грант на создание питомника (фр. pépinière) тутовых деревьев. Спустя три года парламент Корсики отозвал концессию, якобы из-за невыполнения её условий. При этом на семье Буонапарте остались большие долги и обязательство вернуть грант[12][31]. 24 февраля 1785 года отец умер[32][33], и Наполеон взял на себя роль главы семьи, хотя по правилам это должен был  его старший брат Жозеф. 28 сентября того же года он досрочно окончил образование и 3 ноября начал свою профессиональную карьеру в артиллерийском полку де Ла Фер в Валансе в чине младшего лейтенанта артиллерии[34] (офицерский патент был датирован 1 сентября, чин был окончательно подтверждён 10 января 1786 года после трёхмесячного испытательного срока)[35][36].\"\n",
    "x2 = vec.transform([test_3])\n",
    "model.predict_proba(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7109292e86fe758e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ad031c50c2bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1a8d37c3bca1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "683a9c91068654",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:46:33.086584Z",
     "start_time": "2025-04-02T15:46:33.006510Z"
    }
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(2, 5))\n",
    "model = LogisticRegression(max_iter=1000, random_state=SEED, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3986b28faa6ca5b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:49:02.733634Z",
     "start_time": "2025-04-02T15:46:33.716772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    122992\n",
      "           1       1.00      0.96      0.98    122404\n",
      "\n",
      "    accuracy                           0.98    245396\n",
      "   macro avg       0.98      0.98      0.98    245396\n",
      "weighted avg       0.98      0.98      0.98    245396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_baseline_model_2(general_dataset, model, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec5b3b633a6bb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be62e7e9bf90488f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:50:44.572044Z",
     "start_time": "2025-04-02T15:50:44.491437Z"
    }
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(2, 5))\n",
    "model = LogisticRegression(max_iter=1000, random_state=SEED, solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6345384d01e7abc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:53:06.697897Z",
     "start_time": "2025-04-02T15:50:44.944543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    122992\n",
      "           1       1.00      0.96      0.98    122404\n",
      "\n",
      "    accuracy                           0.98    245396\n",
      "   macro avg       0.98      0.98      0.98    245396\n",
      "weighted avg       0.98      0.98      0.98    245396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_baseline_model_2(general_dataset, model, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1a362053d1303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe4ac575057523b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:54:17.906673Z",
     "start_time": "2025-04-02T15:54:17.826672Z"
    }
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(2, 5))\n",
    "model = LogisticRegression(max_iter=1000, random_state=SEED, solver='newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e57d6afd6e68c7e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:56:07.780079Z",
     "start_time": "2025-04-02T15:54:17.978964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    122992\n",
      "           1       1.00      0.95      0.97    122404\n",
      "\n",
      "    accuracy                           0.97    245396\n",
      "   macro avg       0.97      0.97      0.97    245396\n",
      "weighted avg       0.97      0.97      0.97    245396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_baseline_model_2(general_dataset, model, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db0baa1ac427a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e31f00b5ec3421b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf5b2a2a06c53138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:56:07.853120Z",
     "start_time": "2025-04-02T15:56:07.780582Z"
    }
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(2, 5))\n",
    "model = LogisticRegression(max_iter=1000, random_state=SEED, solver='sag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee1e20137d981ad1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:58:13.202432Z",
     "start_time": "2025-04-02T15:56:07.853120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    122992\n",
      "           1       1.00      0.96      0.98    122404\n",
      "\n",
      "    accuracy                           0.98    245396\n",
      "   macro avg       0.98      0.98      0.98    245396\n",
      "weighted avg       0.98      0.98      0.98    245396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_baseline_model_2(general_dataset, model, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a2a25d1e7fe3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39350bd9e421b99a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a1deee1d96ddfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T16:01:08.392903Z",
     "start_time": "2025-04-02T16:01:08.317173Z"
    }
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(2, 5))\n",
    "model = LogisticRegression(max_iter=1000, random_state=SEED, solver='liblinear', penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7acd6d0a2e876201",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-02T16:01:10.673005Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    122992\n",
      "           1       1.00      0.98      0.99    122404\n",
      "\n",
      "    accuracy                           0.99    245396\n",
      "   macro avg       0.99      0.99      0.99    245396\n",
      "weighted avg       0.99      0.99      0.99    245396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_baseline_model_2(general_dataset, model, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153f082865fea761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T16:51:03.930475Z",
     "start_time": "2025-04-02T16:51:03.928140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(2, 5))\n",
    "model = LogisticRegression(max_iter=10000, random_state=SEED, solver='liblinear', penalty='l1')"
   ],
   "id": "cf3743fe06225d3f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T16:53:29.784538Z",
     "start_time": "2025-04-02T16:51:18.875947Z"
    }
   },
   "cell_type": "code",
   "source": "train_baseline_model_2(general_dataset, model, vec)",
   "id": "e7bc368b956ccf30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    122992\n",
      "           1       1.00      0.98      0.99    122404\n",
      "\n",
      "    accuracy                           0.99    245396\n",
      "   macro avg       0.99      0.99      0.99    245396\n",
      "weighted avg       0.99      0.99      0.99    245396\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce8abd766066d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3862505ec3ba959f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "63ef15b3daeaf190"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T16:57:37.218828Z",
     "start_time": "2025-04-02T16:57:37.215860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(2, 5))\n",
    "model = LogisticRegression(max_iter=10000, random_state=SEED, solver='saga', penalty='elasticnet', l1_ratio=0.1)"
   ],
   "id": "be3ea66a786747c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-02T16:57:38.012438Z"
    }
   },
   "cell_type": "code",
   "source": "train_baseline_model_2(general_dataset, model, vec)",
   "id": "1427eb0fb22779a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7beef57d01bae367"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa043be7968ed8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1687eec6ee76b7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:36:05.076891Z",
     "start_time": "2025-04-02T15:36:03.682118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     25132\n",
      "           1       0.94      0.95      0.95     25184\n",
      "\n",
      "    accuracy                           0.95     50316\n",
      "   macro avg       0.95      0.95      0.95     50316\n",
      "weighted avg       0.95      0.95      0.95     50316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "model = MultinomialNB()\n",
    "\n",
    "train_baseline_model_2(dataset, model=model, vectorizer=vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573e2403f96e9500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7866e652f56a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172b9acae7e1b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cbf3311575e4fd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:01:03.348513Z",
     "start_time": "2025-04-02T15:01:03.076201Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def train_random_forest_model(df, model, vectorizer):\n",
    "    X = df['text']\n",
    "    y = df['label']\n",
    "\n",
    "    # Разделение на обучающую и тестовую выборки\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "    # Векторизация текста\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    # Обучение модели случайного леса\n",
    "    \n",
    "    model.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Предсказание и оценка\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3581ca6ea4d9984",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:21:17.860266Z",
     "start_time": "2025-04-02T15:21:17.857267Z"
    }
   },
   "outputs": [],
   "source": [
    "vec_2 = TfidfVectorizer(analyzer='char', ngram_range=(2, 5))\n",
    "model_2 = RandomForestClassifier(random_state=SEED, n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a844b1dca65edf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:24:08.096950Z",
     "start_time": "2025-04-02T15:21:18.369414Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtrain_random_forest_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvec_2\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 18\u001B[39m, in \u001B[36mtrain_random_forest_model\u001B[39m\u001B[34m(df, model, vectorizer)\u001B[39m\n\u001B[32m     14\u001B[39m X_test_vec = vectorizer.transform(X_test)\n\u001B[32m     16\u001B[39m \u001B[38;5;66;03m# Обучение модели случайного леса\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_vec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[38;5;66;03m# Предсказание и оценка\u001B[39;00m\n\u001B[32m     21\u001B[39m y_pred = model.predict(X_test_vec)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitReps\\moderator\\.venv\\Lib\\site-packages\\sklearn\\base.py:1351\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1344\u001B[39m     estimator._validate_params()\n\u001B[32m   1346\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1347\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1348\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1349\u001B[39m     )\n\u001B[32m   1350\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1351\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitReps\\moderator\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001B[39m, in \u001B[36mBaseForest.fit\u001B[39m\u001B[34m(self, X, y, sample_weight)\u001B[39m\n\u001B[32m    478\u001B[39m trees = [\n\u001B[32m    479\u001B[39m     \u001B[38;5;28mself\u001B[39m._make_estimator(append=\u001B[38;5;28;01mFalse\u001B[39;00m, random_state=random_state)\n\u001B[32m    480\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_more_estimators)\n\u001B[32m    481\u001B[39m ]\n\u001B[32m    483\u001B[39m \u001B[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001B[39;00m\n\u001B[32m    484\u001B[39m \u001B[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001B[39;00m\n\u001B[32m    485\u001B[39m \u001B[38;5;66;03m# making threading more efficient than multiprocessing in\u001B[39;00m\n\u001B[32m    486\u001B[39m \u001B[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001B[39;00m\n\u001B[32m    487\u001B[39m \u001B[38;5;66;03m# parallel_backend contexts set at a higher level,\u001B[39;00m\n\u001B[32m    488\u001B[39m \u001B[38;5;66;03m# since correctness does not rely on using threads.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m489\u001B[39m trees = \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    490\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    491\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    492\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprefer\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mthreads\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    493\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    494\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_parallel_build_trees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    495\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    496\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    497\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    498\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    499\u001B[39m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    500\u001B[39m \u001B[43m        \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    501\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    502\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    503\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    504\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    505\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    506\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    507\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    508\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    510\u001B[39m \u001B[38;5;66;03m# Collect newly grown trees\u001B[39;00m\n\u001B[32m    511\u001B[39m \u001B[38;5;28mself\u001B[39m.estimators_.extend(trees)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitReps\\moderator\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     62\u001B[39m config = get_config()\n\u001B[32m     63\u001B[39m iterable_with_config = (\n\u001B[32m     64\u001B[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[32m     65\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     66\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m67\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitReps\\moderator\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1863\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1861\u001B[39m     output = \u001B[38;5;28mself\u001B[39m._get_sequential_output(iterable)\n\u001B[32m   1862\u001B[39m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m1863\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1865\u001B[39m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[32m   1866\u001B[39m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[32m   1867\u001B[39m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[32m   1868\u001B[39m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[32m   1869\u001B[39m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[32m   1870\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitReps\\moderator\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1792\u001B[39m, in \u001B[36mParallel._get_sequential_output\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1790\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_batches += \u001B[32m1\u001B[39m\n\u001B[32m   1791\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_tasks += \u001B[32m1\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1792\u001B[39m res = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1793\u001B[39m \u001B[38;5;28mself\u001B[39m.n_completed_tasks += \u001B[32m1\u001B[39m\n\u001B[32m   1794\u001B[39m \u001B[38;5;28mself\u001B[39m.print_progress()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitReps\\moderator\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001B[39m, in \u001B[36m_FuncWrapper.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    127\u001B[39m     config = {}\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(**config):\n\u001B[32m--> \u001B[39m\u001B[32m129\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitReps\\moderator\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001B[39m, in \u001B[36m_parallel_build_trees\u001B[39m\u001B[34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001B[39m\n\u001B[32m    189\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m class_weight == \u001B[33m\"\u001B[39m\u001B[33mbalanced_subsample\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    190\u001B[39m         curr_sample_weight *= compute_sample_weight(\u001B[33m\"\u001B[39m\u001B[33mbalanced\u001B[39m\u001B[33m\"\u001B[39m, y, indices=indices)\n\u001B[32m--> \u001B[39m\u001B[32m192\u001B[39m     \u001B[43mtree\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    193\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    194\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    195\u001B[39m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcurr_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    196\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    197\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    198\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    199\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    200\u001B[39m     tree._fit(\n\u001B[32m    201\u001B[39m         X,\n\u001B[32m    202\u001B[39m         y,\n\u001B[32m   (...)\u001B[39m\u001B[32m    205\u001B[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001B[32m    206\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitReps\\moderator\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001B[39m, in \u001B[36mBaseDecisionTree._fit\u001B[39m\u001B[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001B[39m\n\u001B[32m    461\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    462\u001B[39m     builder = BestFirstTreeBuilder(\n\u001B[32m    463\u001B[39m         splitter,\n\u001B[32m    464\u001B[39m         min_samples_split,\n\u001B[32m   (...)\u001B[39m\u001B[32m    469\u001B[39m         \u001B[38;5;28mself\u001B[39m.min_impurity_decrease,\n\u001B[32m    470\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m472\u001B[39m \u001B[43mbuilder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtree_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    474\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.n_outputs_ == \u001B[32m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_classifier(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    475\u001B[39m     \u001B[38;5;28mself\u001B[39m.n_classes_ = \u001B[38;5;28mself\u001B[39m.n_classes_[\u001B[32m0\u001B[39m]\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "train_random_forest_model(dataset, model_2, vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18a6a409e25badba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:17:13.081914Z",
     "start_time": "2025-04-02T15:17:11.174660Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LGBMClassifier.fit() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 75\u001B[39m\n\u001B[32m     65\u001B[39m lgbm_model = LGBMClassifier(\n\u001B[32m     66\u001B[39m     n_estimators=\u001B[32m100\u001B[39m,\n\u001B[32m     67\u001B[39m     max_depth=\u001B[32m7\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     71\u001B[39m     n_jobs=-\u001B[32m1\u001B[39m\n\u001B[32m     72\u001B[39m )\n\u001B[32m     74\u001B[39m \u001B[38;5;66;03m# Предполагается, что df — DataFrame с колонками 'text' и 'label'\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m75\u001B[39m \u001B[43mtrain_lgbm_model_with_live_progress\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlgbm_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvectorizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_iterations\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 35\u001B[39m, in \u001B[36mtrain_lgbm_model_with_live_progress\u001B[39m\u001B[34m(df, model, vectorizer, seed, num_iterations)\u001B[39m\n\u001B[32m     32\u001B[39m eval_set = [(X_train_vec, y_train), (X_test_vec, y_test)]\n\u001B[32m     34\u001B[39m \u001B[38;5;66;03m# Обучение модели с колбэком для tqdm\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m35\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     36\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX_train_vec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[43m    \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     38\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_set\u001B[49m\u001B[43m=\u001B[49m\u001B[43meval_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     39\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_metric\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlogloss\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     40\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     41\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mTqdmCallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_iterations\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m     42\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     44\u001B[39m \u001B[38;5;66;03m# Предсказание и оценка\u001B[39;00m\n\u001B[32m     45\u001B[39m y_pred = model.predict(X_test_vec)\n",
      "\u001B[31mTypeError\u001B[39m: LGBMClassifier.fit() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Кастомный колбэк для отображения прогресса с tqdm\n",
    "class TqdmCallback:\n",
    "    def __init__(self, total):\n",
    "        self.total = total\n",
    "        self.pbar = tqdm(total=total)\n",
    "\n",
    "    def __call__(self, env):\n",
    "        self.pbar.update(1)\n",
    "        if env.iteration + 1 == self.total:\n",
    "            self.pbar.close()\n",
    "\n",
    "def train_lgbm_model_with_live_progress(df, model, vectorizer, seed=42, num_iterations=100):\n",
    "    X = df['text']\n",
    "    y = df['label']\n",
    "\n",
    "    # Разделение данных\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed\n",
    "    )\n",
    "\n",
    "    # Векторизация текста\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    # Задаем eval_set для мониторинга\n",
    "    eval_set = [(X_train_vec, y_train), (X_test_vec, y_test)]\n",
    "\n",
    "    # Обучение модели с колбэком для tqdm\n",
    "    model.fit(\n",
    "        X_train_vec,\n",
    "        y_train,\n",
    "        eval_set=eval_set,\n",
    "        eval_metric='logloss',\n",
    "        verbose=10,\n",
    "        callbacks=[TqdmCallback(total=num_iterations)]\n",
    "    )\n",
    "\n",
    "    # Предсказание и оценка\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # График по итогам обучения (если нужно)\n",
    "    results = model.evals_result_\n",
    "    epochs = range(len(results['training']['logloss']))\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, results['training']['logloss'], label='Train')\n",
    "    plt.plot(epochs, results['valid_1']['logloss'], label='Test')\n",
    "    plt.xlabel('Итерации')\n",
    "    plt.ylabel('Logloss')\n",
    "    plt.title('Прогресс обучения LightGBM')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Пример использования:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "lgbm_model = LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Предполагается, что df — DataFrame с колонками 'text' и 'label'\n",
    "train_lgbm_model_with_live_progress(dataset, lgbm_model, vectorizer, num_iterations=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4179794803900b42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T15:28:16.887923Z",
     "start_time": "2025-04-02T15:28:16.646390Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier, log_evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Кастомный колбэк для отображения прогресс-бара с tqdm\n",
    "class TqdmCallback:\n",
    "    def __init__(self, total):\n",
    "        self.total = total\n",
    "        self.pbar = tqdm(total=total)\n",
    "\n",
    "    def __call__(self, env):\n",
    "        self.pbar.update(1)\n",
    "        if env.iteration + 1 == self.total:\n",
    "            self.pbar.close()\n",
    "\n",
    "def train_lgbm_model_with_live_progress(df, model, vectorizer, seed=42, num_iterations=100):\n",
    "    X = df['text']\n",
    "    y = df['label']\n",
    "\n",
    "    # Разбивка данных\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=seed\n",
    "    )\n",
    "\n",
    "    # Векторизация текста\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    # Определяем eval_set для мониторинга\n",
    "    eval_set = [(X_train_vec, y_train), (X_test_vec, y_test)]\n",
    "\n",
    "    # Обучение модели с использованием колбэков:\n",
    "    # - log_evaluation: выводит logloss каждые 10 итераций\n",
    "    # - TqdmCallback: отображает прогресс-бар\n",
    "    model.fit(\n",
    "        X_train_vec, y_train,\n",
    "        eval_set=eval_set,\n",
    "        eval_metric='logloss',\n",
    "        callbacks=[log_evaluation(10), TqdmCallback(total=num_iterations)]\n",
    "    )\n",
    "\n",
    "    # Предсказание и оценка модели\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Визуализация прогресса обучения\n",
    "    results = model.evals_result_\n",
    "    epochs = range(len(results['training']['logloss']))\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, results['training']['logloss'], label='Train')\n",
    "    plt.plot(epochs, results['valid_1']['logloss'], label='Test')\n",
    "    plt.xlabel('Итерации')\n",
    "    plt.ylabel('Logloss')\n",
    "    plt.title('Прогресс обучения LightGBM')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7004fea8f3b318d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-02T15:28:16.968369Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 100606, number of negative: 100658\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.922805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 406399\n",
      "[LightGBM] [Info] Number of data points in the train set: 201264, number of used features: 15428\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:03<00:08,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's binary_logloss: 0.686386\tvalid_1's binary_logloss: 0.686593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:03<00:05, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's binary_logloss: 0.680805\tvalid_1's binary_logloss: 0.681195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [00:04<00:03, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttraining's binary_logloss: 0.676038\tvalid_1's binary_logloss: 0.676569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [00:04<00:02, 19.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40]\ttraining's binary_logloss: 0.671975\tvalid_1's binary_logloss: 0.672662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [00:05<00:02, 19.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttraining's binary_logloss: 0.668498\tvalid_1's binary_logloss: 0.669349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [00:05<00:01, 20.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60]\ttraining's binary_logloss: 0.665508\tvalid_1's binary_logloss: 0.666501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [00:06<00:01, 20.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\ttraining's binary_logloss: 0.662903\tvalid_1's binary_logloss: 0.664025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [00:06<00:00, 20.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80]\ttraining's binary_logloss: 0.660606\tvalid_1's binary_logloss: 0.661857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [00:07<00:00, 20.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90]\ttraining's binary_logloss: 0.658573\tvalid_1's binary_logloss: 0.659934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 13.40it/s]"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "lgbm_model = LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=100,\n",
    "    learning_rate=0.005,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Предполагается, что df — DataFrame с колонками 'text' и 'label'\n",
    "train_lgbm_model_with_live_progress(dataset, lgbm_model, vectorizer, num_iterations=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f805d463553c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
